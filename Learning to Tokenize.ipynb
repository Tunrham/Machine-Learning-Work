{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################\n",
    "##### Tokenization Process #####\n",
    "################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Necessary Libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# Importing Tokeniztion libraries\n",
    "## keras module for building LSTM \n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.models import Sequential\n",
    "import keras.utils as ku \n",
    "\n",
    "import warnings\n",
    "\n",
    "\n",
    "# Going to import this random Tokenizer Module\n",
    "import tokenize as tk\n",
    "\n",
    "## word_idx = tokenizer.word_index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>match_id</th>\n",
       "      <th>Pt</th>\n",
       "      <th>Set1</th>\n",
       "      <th>Set2</th>\n",
       "      <th>Gm1</th>\n",
       "      <th>Gm2</th>\n",
       "      <th>Pts</th>\n",
       "      <th>SrvDueceSide</th>\n",
       "      <th>Gm#</th>\n",
       "      <th>TbSet</th>\n",
       "      <th>...</th>\n",
       "      <th>PtsAfter</th>\n",
       "      <th>GmW</th>\n",
       "      <th>Gm1.1</th>\n",
       "      <th>Gm2.1</th>\n",
       "      <th>SetW</th>\n",
       "      <th>Set1.1</th>\n",
       "      <th>Set2.1</th>\n",
       "      <th>RevTB</th>\n",
       "      <th>TBrev</th>\n",
       "      <th>rallyCount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>20070905-M-US_Open-QF-Roger_Federer-Andy_Roddick</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>15-15</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>30-15</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>20070905-M-US_Open-QF-Roger_Federer-Andy_Roddick</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>30-30</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>40-30</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>20070905-M-US_Open-QF-Roger_Federer-Andy_Roddick</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>40-40</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>AD-40</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20070905-M-US_Open-QF-Roger_Federer-Andy_Roddick</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>30-0</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>40-0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>20070905-M-US_Open-QF-Roger_Federer-Andy_Roddick</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0-0</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>15-0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 53 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            match_id  Pt  Set1  Set2  Gm1  \\\n",
       "7   20070905-M-US_Open-QF-Roger_Federer-Andy_Roddick   8     0     0    1   \n",
       "9   20070905-M-US_Open-QF-Roger_Federer-Andy_Roddick  10     0     0    1   \n",
       "11  20070905-M-US_Open-QF-Roger_Federer-Andy_Roddick  12     0     0    1   \n",
       "19  20070905-M-US_Open-QF-Roger_Federer-Andy_Roddick  20     0     0    2   \n",
       "26  20070905-M-US_Open-QF-Roger_Federer-Andy_Roddick  27     0     0    3   \n",
       "\n",
       "    Gm2    Pts  SrvDueceSide  Gm#  TbSet    ...      PtsAfter  GmW  Gm1.1  \\\n",
       "7     0  15-15          True    2      1    ...         30-15    0      1   \n",
       "9     0  30-30          True    2      1    ...         40-30    0      1   \n",
       "11    0  40-40          True    2      1    ...         AD-40    0      1   \n",
       "19    1   30-0          True    4      1    ...          40-0    0      2   \n",
       "26    2    0-0          True    6      1    ...          15-0    0      3   \n",
       "\n",
       "    Gm2.1 SetW Set1.1 Set2.1 RevTB TBrev rallyCount  \n",
       "7       0    0      0      0   NaN   NaN          1  \n",
       "9       0    0      0      0   NaN   NaN          7  \n",
       "11      0    0      0      0   NaN   NaN          5  \n",
       "19      1    0      0      0   NaN   NaN          3  \n",
       "26      2    0      0      0   NaN   NaN          1  \n",
       "\n",
       "[5 rows x 53 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing the Data Set\n",
    "\n",
    "## This is the Original Federer vs Roddick Dataset\n",
    "fr = pd.read_csv('FedRod.csv')\n",
    "\n",
    "### This is the dataset where only Andy Roddick is Serving\n",
    "ar_serve = fr[(fr['Serving']== 'AR')]\n",
    "\n",
    "#### This is the dataset where Andy Roddick is only Serving to the Duece Side\n",
    "ar_d_srv = ar_serve[(ar_serve['SrvDueceSide'])==True]\n",
    "\n",
    "##### This is the dataset which only uses points where the First Serve Went In\n",
    "ar_token = ar_d_srv[(ar_d_srv['Sv2'].isnull())]\n",
    "\n",
    "###### Let's Double Check\n",
    "ar_token.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 f38 f3 b3 b3 b2 f1 f1 f3 s3 b2 b1*\n"
     ]
    }
   ],
   "source": [
    "# Let's simplify this process even further by trying to split just one string\n",
    "\n",
    "## In this String, Roddick hit's a first serve in and loses an 11 Shot Rally\n",
    "string = '5f38f3b3b3b2f1f1f3s3b2b1*'\n",
    "\n",
    "### We want to split the string\n",
    "string = string.replace(\"f\", \" f\")\n",
    "string = string.replace(\"b\", \" b\")\n",
    "string = string.replace(\"r\", \" r\")\n",
    "string = string.replace(\"s\", \" s\")\n",
    "string = string.replace(\"v\", \" v\")\n",
    "string = string.replace(\"z\", \" z\")\n",
    "string = string.replace(\"o\", \" o\")\n",
    "string = string.replace(\"p\", \" p\")\n",
    "string = string.replace(\"l\", \" l\")\n",
    "string = string.replace(\"m\", \" m\")\n",
    "string = string.replace(\"h\", \" h\")\n",
    "string = string.replace(\"i\", \" i\")\n",
    "string = string.replace(\"j\", \" j\")\n",
    "string = string.replace(\"k\", \" k\")\n",
    "string = string.replace(\"t\", \" t\")\n",
    "string = string.replace(\"q\", \" q\")\n",
    "\n",
    "\n",
    "print(string)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Below we will create a Function that splits a Rally Sequence by each Shot\n",
    "\n",
    "def token_maker(string):\n",
    "    string = string.replace(\"f\", \" f\")\n",
    "    string = string.replace(\"b\", \" b\")\n",
    "    string = string.replace(\"r\", \" r\")\n",
    "    string = string.replace(\"s\", \" s\")\n",
    "    string = string.replace(\"v\", \" v\")\n",
    "    string = string.replace(\"z\", \" z\")\n",
    "    string = string.replace(\"o\", \" o\")\n",
    "    string = string.replace(\"p\", \" p\")\n",
    "    string = string.replace(\"l\", \" l\")\n",
    "    string = string.replace(\"m\", \" m\")\n",
    "    string = string.replace(\"h\", \" h\")\n",
    "    string = string.replace(\"i\", \" i\")\n",
    "    string = string.replace(\"j\", \" j\")\n",
    "    string = string.replace(\"k\", \" k\")\n",
    "    string = string.replace(\"t\", \" t\")\n",
    "    string = string.replace(\"q\", \" q\")\n",
    "    \n",
    "    return print(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 s27 f+1 f2 v#\n",
      "4w\n",
      "6n\n",
      "6 f2d#\n",
      "4 f28 f3 s3 f1 f3 s3 b3 b2 f3w@\n",
      "6n\n",
      "6*\n",
      "5 s2d#\n",
      "5 f38 f3 b3 b3 b2 f1 f1 f3 s3 b2 b1*\n",
      "5 s28 f+3 b2 z3 b2 v2 r3x#\n"
     ]
    }
   ],
   "source": [
    "# Here we are creating a Test Dataset for Testing our Token Creating Function\n",
    "\n",
    "tester = pd.read_csv('TestToken.csv')\n",
    "\n",
    "c = 0\n",
    "\n",
    "while c < len(tester.index):\n",
    "    token_maker(tester.iloc[c,15])\n",
    "    c=c+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is going to be pretty ugly, but, I'm going to:\n",
    "# Create a CSV of the Roddick Duece Side 1st Sv In Data ONLY\n",
    "# and then run the function against that data, then copy paste the output\n",
    "# into a new row (I know this can be done in python I'm just completely\n",
    "# blanking on it at the moment). This will give us tokenized data at least!\n",
    "\n",
    "ar_token.to_csv(r\"C:\\Users\\nicho\\Desktop\\Udemy Python\\Machine Learning (UTS)\\Assignment 2\\ar_token.csv\")\n",
    "\n",
    "# (This can be ignored for now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 s2d#\n",
      "5 s28 f+3 b2 z3 b2 v2 r3x#\n",
      "4 f27 f+3 b1 v1*\n",
      "5 s29 f1 f1n@\n",
      "4+ f#\n",
      "4+*\n",
      "5 b2n#\n",
      "6*\n",
      "6*\n",
      "6*\n",
      "6 s28 f1 f3n@\n",
      "5 s#\n",
      "4 f2d#\n",
      "4 f2n#\n",
      "4 f2d#\n",
      "6 s27 f-3*\n",
      "4 f38 b2 b-1*\n",
      "4*\n",
      "4 f#\n",
      "6 s#\n",
      "5 b3w#\n",
      "6 b#\n",
      "5 s2n#\n",
      "4 f28 f+3 s1n#\n",
      "4 r27 f+1 f1 v3 s1d#\n",
      "6 s38 b3 s3 b1 f1d@\n",
      "4*\n",
      "6 s#\n",
      "4 f39 b2 f1 f2 f2 f+3 s2 v3*\n",
      "4 r2n#\n",
      "4 f28 f+3 b2 z1 l2 o3*\n",
      "4 f3w#\n",
      "5 s28 f+3*\n",
      "c4 f28 s3 b1n@\n",
      "6*\n",
      "6*\n",
      "5 s27 f+2 b2 z2 f1 v1w#\n",
      "4 f18 f3w#\n",
      "5 b;27 f-2*\n",
      "6 b3w#\n",
      "6 b2d#\n",
      "6 b38 f3 b1*\n",
      "4 f1d#\n",
      "5 f28 f2 f2 f3 b3 b3 s1 f1 f3*\n",
      "4 f2n#\n",
      "4 f27 f3*\n",
      "4+ f38*\n",
      "4 f27 f+-3 b1d#\n",
      "6*\n",
      "6*\n",
      "5 b18 f1 f1n#\n",
      "4+ f17 f-2 i=3*\n",
      "6 b28 f1 f1 v+-3 b1*\n",
      "4 f29 f2 s2 f1 f1 f3d#\n",
      "4 f29 b3 b1 f3+ b3*\n",
      "4 f29 f3 b3 f+-1 l2 o3*\n",
      "5 s28 f1 f1 f3+ s1*\n",
      "4 f1d#\n",
      "4 f29*\n",
      "6 b27 f+-2 f2 z-3*\n",
      "c4 f28 f3+ b3*\n",
      "c4 f29 b2 f+-3*\n",
      "4 f1w#\n",
      "c6 s27 f+3d@\n",
      "4 f29 f+3 b1*\n",
      "4 f28 b+3 b3 z1 f1*\n",
      "4#\n",
      "4#\n",
      "4+ f v3n@\n",
      "4 r29 f+3 b3 z1 l2d#\n",
      "4 f28 f+1 l#\n",
      "6 b38 b+3 b3 z3 m#\n",
      "4#\n",
      "4 f39 b3 b2 f3 b2 f3 b3n@\n",
      "4 f29 s3 b3 b3 b1 f1 f+3 b1*\n",
      "6#\n",
      "4 f19 f2 s3 b3 b3 f3 b1*\n",
      "4 r29 f+3 b3 z1*\n",
      "6#\n",
      "4 f18 f+3 b3 z1 l3 o3 m1 f2 o3*\n",
      "4 f19 f+3 b1n#\n",
      "4*\n",
      "6#\n",
      "4#\n",
      "6*\n",
      "6 s27 f+3 b3 z1*\n",
      "4 f38 b3 b1 f1 f1 f3 s3 s+3 b1n@\n",
      "4 f28 f3 b2 f1 f1 f3 s3 b3n@\n",
      "6 s;27 f#\n",
      "4 f39 b3 b1 f1 f1 r#\n",
      "4 f29 b3 b+1*\n",
      "6 s#\n",
      "4 f27 f+3 m3w#\n",
      "4 f38 f1 r#\n",
      "4 f28 f+3 b3w#\n",
      "4 f29 f3 b3 f1 f#\n",
      "4 f#\n",
      "6*\n",
      "4 r29 f3 b3 f1n@\n",
      "6 s39 f+3 s3 z1n@\n",
      "4 f39 s2 f1 f2 s2 b1n@\n",
      "4 f38 b3 s1 f1 f3 s3 b2 f1 f3 b+1 f1*\n",
      "6 s19 f1 f3 b3n#\n",
      "4 f#\n",
      "c4 f39 b3 s#\n",
      "4 f18 f+2 b1 v1n@\n",
      "4 f28 f+2 b3 z3 b3*\n",
      "4+ f17 v1*\n",
      "4+ f27 h3d#\n",
      "6*\n",
      "5 s28 f#\n",
      "4 r28 f+3 s3 z1n@\n",
      "6 s3x#\n",
      "6*\n",
      "4*\n",
      "4*\n",
      "5 b17 f+1 f2 i2*\n",
      "5 b28 f+3 b2n@\n",
      "5 s28 f1 f3*\n",
      "4 f38*\n",
      "6*\n",
      "5*\n",
      "6*\n",
      "4 f17 f+3n@\n",
      "5 s#\n",
      "6*\n",
      "4 f39 b2d#\n",
      "6*\n",
      "4 f#\n",
      "4 r17 f+3d@\n",
      "4 r2n#\n",
      "6 b28 f3 s1 f1 f3w@\n",
      "4 f2d#\n",
      "6 b#\n",
      "6 s28 f1 f1 r1 f1n@\n",
      "6 s#\n",
      "6 b2n#\n",
      "4 f;27 f+1*\n",
      "c5 b28 f2 f3 b3 s3 b2 f3 b2 f1 f1 f2 b3n@\n",
      "4*\n",
      "R\n",
      "4+ f28 z3w#\n",
      "4 r28 f3d@\n",
      "5 b28 b2 f1d@\n",
      "4 f28*\n",
      "4 f38 s2 f+1 f3n#\n",
      "4 f#\n",
      "4 f27 f+3 b3 z2d#\n",
      "cc4 f28 b2 b2 b3 b2 b2 b2 f3d@\n",
      "5 s28 b2 f3 b3 b2 f2 f2 b3 b3 b2 b2 f3x@\n",
      "5 b18 f1 f2 f3 b2 f2 f1 f2 f1 f2 f1 f2n#\n",
      "4*\n",
      "5 s2n#\n",
      "4 f38 s2n@\n",
      "4 f2n#\n",
      "4 f28 f+3 s2 v1*\n",
      "5 s29 f1 f2n#\n",
      "4 f27 f+2 b2d@\n",
      "4 f28 f2 b2 f1 r2d#\n",
      "5 s29 f3 s2 f+3 m2 o2 l2d#\n",
      "5 s#\n",
      "4 r28 f1x@\n",
      "4 f2n#\n",
      "5 s28 f1 f2 f+3 b1 v#\n",
      "4 f28 f3 s3 f3 b3 b3 b2 f1 f1 f2 f1 f2 s3w@\n",
      "5 s28 b1 f1 f1 f2 b2 b2 f1w@\n",
      "5 s28 f1 f2 f+3 m2 o2*\n",
      "4 f28 f1 r2 f+3 b2n#\n",
      "4 f29 b2n#\n",
      "5 b17 f+3 m3 o2 f#\n",
      "5 s28 f+1 f1 v1 r2 z2*\n",
      "4 f2d#\n",
      "5 s27 f+3 s1 v1*\n",
      "5 s28 f+1 f2 v3 m2d#\n",
      "4 f29 b2 b+1 f2 z3*\n",
      "4 r28 f+3 b3 i2*\n",
      "6*\n",
      "S\n",
      "4 f19 f2 f1 f1 f1 f2 s2 f3 s3 f3 b1x@\n",
      "6 s29 f3n@\n",
      "6*\n",
      "6 s38 f3 b3 f3 b3 f2 f1 f1 f3 b3n@\n",
      "4 r17 f-3*\n",
      "6 s38 b3 b3d@\n",
      "6 s27 f+3 b1 v1 f3*\n",
      "4 f#\n",
      "4 f27 f+3 b1*\n",
      "4*\n",
      "6 s37 b+3n@\n",
      "4 r28 s+1*\n",
      "4 r39 b3 s1 f1n@\n",
      "6+ s17 v1*\n",
      "4 f27 f+3 m3 o=3 s2 f+1 f1 v3 s1*\n",
      "4*\n",
      "4*\n",
      "4 r3w#\n",
      "6 s2n#\n"
     ]
    }
   ],
   "source": [
    "# Below I am just testing the function above for formatting the data so that it can be tokenized\n",
    "\n",
    "tester = pd.read_csv('ar_token.csv')\n",
    "\n",
    "c = 0\n",
    "\n",
    "while c < len(tester.index):\n",
    "    token_maker(tester.iloc[c,16])\n",
    "    c=c+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>match_id</th>\n",
       "      <th>Pt</th>\n",
       "      <th>Set1</th>\n",
       "      <th>Set2</th>\n",
       "      <th>Gm1</th>\n",
       "      <th>Gm2</th>\n",
       "      <th>Pts</th>\n",
       "      <th>SrvDueceSide</th>\n",
       "      <th>Gm#</th>\n",
       "      <th>...</th>\n",
       "      <th>PtsAfter</th>\n",
       "      <th>GmW</th>\n",
       "      <th>Gm1.1</th>\n",
       "      <th>Gm2.1</th>\n",
       "      <th>SetW</th>\n",
       "      <th>Set1.1</th>\n",
       "      <th>Set2.1</th>\n",
       "      <th>RevTB</th>\n",
       "      <th>TBrev</th>\n",
       "      <th>rallyCount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>20070905-M-US_Open-QF-Roger_Federer-Andy_Roddick</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>15-15</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>30-15</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>20070905-M-US_Open-QF-Roger_Federer-Andy_Roddick</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>30-30</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>40-30</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11</td>\n",
       "      <td>20070905-M-US_Open-QF-Roger_Federer-Andy_Roddick</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>40-40</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>AD-40</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19</td>\n",
       "      <td>20070905-M-US_Open-QF-Roger_Federer-Andy_Roddick</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>30-0</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>40-0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26</td>\n",
       "      <td>20070905-M-US_Open-QF-Roger_Federer-Andy_Roddick</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0-0</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>15-0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 54 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                          match_id  Pt  Set1  \\\n",
       "0           7  20070905-M-US_Open-QF-Roger_Federer-Andy_Roddick   8     0   \n",
       "1           9  20070905-M-US_Open-QF-Roger_Federer-Andy_Roddick  10     0   \n",
       "2          11  20070905-M-US_Open-QF-Roger_Federer-Andy_Roddick  12     0   \n",
       "3          19  20070905-M-US_Open-QF-Roger_Federer-Andy_Roddick  20     0   \n",
       "4          26  20070905-M-US_Open-QF-Roger_Federer-Andy_Roddick  27     0   \n",
       "\n",
       "   Set2  Gm1  Gm2    Pts  SrvDueceSide  Gm#    ...      PtsAfter  GmW  Gm1.1  \\\n",
       "0     0    1    0  15-15          True    2    ...         30-15    0      1   \n",
       "1     0    1    0  30-30          True    2    ...         40-30    0      1   \n",
       "2     0    1    0  40-40          True    2    ...         AD-40    0      1   \n",
       "3     0    2    1   30-0          True    4    ...          40-0    0      2   \n",
       "4     0    3    2    0-0          True    6    ...          15-0    0      3   \n",
       "\n",
       "   Gm2.1  SetW Set1.1 Set2.1  RevTB TBrev rallyCount  \n",
       "0      0     0      0      0    NaN   NaN          1  \n",
       "1      0     0      0      0    NaN   NaN          7  \n",
       "2      0     0      0      0    NaN   NaN          5  \n",
       "3      1     0      0      0    NaN   NaN          3  \n",
       "4      2     0      0      0    NaN   NaN          1  \n",
       "\n",
       "[5 rows x 54 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# So below is our now Formatted AR Serving to the FH side \n",
    "t_ar = pd.read_csv('t_ar.csv')\n",
    "t_ar.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4 f39 s2 f1 f2 s2 b1n@'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# OK now we're going to try Count all of the strings in the Tokenized COlumn\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Turning t_ar[1st] into a list\n",
    "\n",
    "list_t_ar = t_ar['1st'].tolist()\n",
    "\n",
    "\n",
    "## This was so that we could tokenize the list\n",
    "## Now we're going to use the tokenizer module\n",
    "## \"Filters ='.'\" was used so that I don't lose values such as @ or # [values important for point endings]\n",
    "\n",
    "tokenizer = Tokenizer(num_words=None, filters='.', lower=True, split = ' ')\n",
    "\n",
    "### Train our tokenziser to the strings (PLEASE WORK!)\n",
    "tokenizer.fit_on_texts(list_t_ar)\n",
    "\n",
    "#### Convert our list of strings into a list of integers\n",
    "sequences = tokenizer.texts_to_sequences(list_t_ar)\n",
    "\n",
    "##### now all of our shots in rally are represented as numbers instead of code\n",
    "##### We now need to map tokenized numbers to values\n",
    "##### Mapping Indexes to Words\n",
    "idx_word = tokenizer.index_word\n",
    "\n",
    "' '.join(idx_word[w] for w in sequences[100][:40])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 26, 19, 2, 8, 19, 48]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Just for Further proof ^^^ This is the same as above\n",
    "\n",
    "sequences[100][:40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We've \"Tokenized\" our data, now we're going give our network a sequence of words, and train the model to predict the next word\n",
    "\n",
    "features = []\n",
    "labels = []\n",
    "\n",
    "training_length = 50\n",
    "\n",
    "## This is the training length used in the example I learnt from\n",
    "## It means we're going to train a sequence with 50 tokens (this seems was too long)\n",
    "## But that's ok we're simply testing at the moment\n",
    "\n",
    "### Now we need to iterate through our sequence of tokens\n",
    "for seq in sequences:\n",
    "    \n",
    "    #### We need to create multiple training examples from each sequence\n",
    "    for i in range(training_length, len(seq)):\n",
    "        \n",
    "        ##### We need to now extract the features and label\n",
    "        extract = seq[i - training_length:i + 1]\n",
    "        \n",
    "        ##### We need to now Set the features and the label\n",
    "        features.append(extract[:-1])\n",
    "        labels.append(extract[-1])\n",
    "        \n",
    "features = np.array(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0,)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'word_idx' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-3f1721bd9f8f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;31m## To do this:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[0mnum_words\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword_idx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;31m## Empty the array to hold labels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'word_idx' is not defined"
     ]
    }
   ],
   "source": [
    "# In order to train the neural network, we need to one-hot encode the labels\n",
    "# This is essentially binarising, so if we had the category \"Colours\" with categories \"Red\" \"Blue\" \" Green:\n",
    "# Our Table would become\n",
    "##############################\n",
    "### Red ### Blue ### Green ###\n",
    "##------###------###-------###\n",
    "###  0  ###   1  ###   0   ###\n",
    "##------###------###-------###\n",
    "###  1  ###   0  ###   0   ###\n",
    "##------###------###-------###\n",
    "\n",
    "\n",
    "\n",
    "## To do this:\n",
    "num_words = len(word_idx) + 1\n",
    "\n",
    "## Empty the array to hold labels\n",
    "label_array = np.zeros((len(features), num_words), dtype = np.int8)\n",
    "\n",
    "## One hot-encode the labels\n",
    "for example_index, word_index in enumerate(labels):\n",
    "    label_array[example_index,word_index] = 1\n",
    "    \n",
    "label_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
